{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 256\n",
    "CHUNK_OVERLAP = 128\n",
    "\n",
    "EMBEDDING_MODEL = \"intfloat/e5-large\"\n",
    "\n",
    "K = 3\n",
    "\n",
    "LLM = \"google/gemma-2-9b-it\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an AI visual assistant surveillance operator that can analyze real-time traffic analysis and accident detection.\n",
    "\n",
    "Respond to user's questions as accurately as possible.\n",
    "Be careful not to answer with false information.\n",
    "\n",
    "Using the provided caption information, describe the scene in a detailed manner.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "QUANTIZATION = \"bf16\" # \"qlora\", \"bf16\", \"fp16\"\n",
    "\n",
    "MAX_NEW_TOKENS = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json(file_path, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):\n",
    "    loader = JSONLoader(\n",
    "        file_path=file_path,\n",
    "        jq_schema=\".frame.[].caption\",\n",
    "        text_content=False,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    \n",
    "    video_doc = \"\"\n",
    "    for doc in docs:\n",
    "        video_doc += doc.page_content\n",
    "        video_doc += '\\n'\n",
    "    \n",
    "    meta_data = {\n",
    "        'source' : file_path\n",
    "    }\n",
    "    \n",
    "    chunks = [Document(page_content=video_doc, metadata=meta_data)]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def create_vector_db(chunks, model_path=EMBEDDING_MODEL):\n",
    "    \"\"\"FAISS DB\"\"\"\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    db = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "def load_vector_db(chunks, model_path=EMBEDDING_MODEL):\n",
    "    \"\"\"FAISS DB\"\"\"\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    db = FAISS.load_local(\n",
    "        './db/th_v1',\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    return db\n",
    "    \n",
    "def process_jsons_from_dataframe(unique_paths, base_directory):\n",
    "    \n",
    "    total_chunks = []\n",
    "    \n",
    "    for path in tqdm(unique_paths, desc=\"Processing JSONs\"):\n",
    "        \n",
    "        normalized_path = unicodedata.normalize('NFC', path)\n",
    "        full_path = os.path.normpath(\n",
    "            os.path.join(\n",
    "                base_directory, normalized_path.lstrip('./')\n",
    "            )\n",
    "        ) if not os.path.isabs(normalized_path) else normalized_path\n",
    "        json_title = os.path.splitext(os.path.basename(full_path))[0]\n",
    "        \n",
    "        print(f\"Processing {json_title}...\")\n",
    "        \n",
    "        chunks = process_json(full_path)\n",
    "\n",
    "        total_chunks.extend(chunks)\n",
    "    \n",
    "    db = create_vector_db(total_chunks)\n",
    "    # db = load_vector_db(total_chunks)\n",
    "    \n",
    "    # Retriever\n",
    "\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={'k': K}\n",
    "    )\n",
    "    \n",
    "    json_databases = {\n",
    "            'db': db,\n",
    "            'retriever': retriever\n",
    "    }\n",
    "    return json_databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_directory = 'data/msrvtt/' # Your Base Directory\n",
    "# os.listdir(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"data/MSR-VTT-1kA/val_list_jsfusion.txt\", 'r')\n",
    "# txt = file.read().split('\\n')\n",
    "# video_path = [idx + '.json' for idx in txt]\n",
    "# len(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs: 100%|██████████| 4/4 [00:00<00:00, 138.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cam_07.mp4-meta_db...\n",
      "Processing cam_06.mp4-meta_db...\n",
      "Processing cam_04.mp4-meta_db...\n",
      "Processing demo_1.mp4-meta_db...\n",
      "CPU times: user 23 s, sys: 949 ms, total: 24 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_directory = '/home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db' # Your Base Directory\n",
    "db_list = [filename for filename in os.listdir(base_directory) if 'meta' in filename]\n",
    "json_databases = process_jsons_from_dataframe(db_list, base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f006222f940>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json_databases['db'].save_local('/home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db/total_video')\n",
    "\n",
    "model_path = EMBEDDING_MODEL\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_path,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "db = FAISS.load_local('/home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db/total_video', embeddings_model, allow_dangerous_deserialization=True)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id : /home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db/cam_04.mp4-meta_db.json\n",
      "=========================================================\n",
      "video_id : /home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db/cam_07.mp4-meta_db.json\n",
      "=========================================================\n",
      "video_id : /home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db/cam_06.mp4-meta_db.json\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "prompt_sample = 'bike accident'\n",
    "\n",
    "docs = json_databases['retriever'].invoke(prompt_sample)\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"video_id : {doc.metadata['source']}\")\n",
    "    # print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id : /home/jiyul/SPS_JY/TeletoVision_demo/public/frontend/static/db/cam_05.mp4-meta_db.json\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "prompt_sample = 'a little girl does gymnastics'\n",
    "\n",
    "docs = json_databases['retriever'].invoke(prompt_sample)\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"video_id : {doc.metadata['source']}\")\n",
    "    # print(doc.page_content)\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/MSR-VTT-1kA/raw-captions.pkl', 'rb') as f:\n",
    "    rc = pickle.load(f)\n",
    "\n",
    "with open('data/MSR-VTT-1kA/jsfusion_val_caption_idx.pkl', 'rb') as f:\n",
    "    jvci = pickle.load(f)\n",
    "\n",
    "len(rc.keys()), len(jvci)\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for video_id, cap_id in jvci.items():\n",
    "    cap = ' '.join(rc[video_id][cap_id])\n",
    "    labels[video_id] = cap\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_recall_at_k(predictions, targets, k):\n",
    "    \"\"\"\n",
    "    Recall@k 계산 함수\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (list of list): 각 query에 대한 예측된 결과 리스트\n",
    "    targets (list): 각 query에 대한 실제 정답\n",
    "    k (int): k 값\n",
    "    \n",
    "    Returns:\n",
    "    float: Recall@k 값\n",
    "    \"\"\"\n",
    "    assert len(predictions) == len(targets), \"Predictions와 Targets의 길이는 동일해야 합니다.\"\n",
    "    \n",
    "    recall_count = 0\n",
    "    for i in range(len(targets)):\n",
    "        if targets[i] in predictions[i][:k]:\n",
    "            recall_count += 1\n",
    "            \n",
    "    return recall_count / len(targets)\n",
    "\n",
    "def compute_mean_rank(predictions, targets):\n",
    "    \"\"\"\n",
    "    Mean Rank 계산 함수\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (list of list): 각 query에 대한 예측된 결과 리스트\n",
    "    targets (list): 각 query에 대한 실제 정답\n",
    "    \n",
    "    Returns:\n",
    "    float: Mean Rank 값\n",
    "    \"\"\"\n",
    "    ranks = []\n",
    "    for i in range(len(targets)):\n",
    "        if targets[i] in predictions[i]:\n",
    "            ranks.append(predictions[i].index(targets[i]) + 1)\n",
    "        else:\n",
    "            ranks.append(len(predictions[i]) + 1)  # 만약 정답이 없다면 max rank로 설정\n",
    "            \n",
    "    return np.mean(ranks)\n",
    "\n",
    "def compute_median_rank(predictions, targets):\n",
    "    \"\"\"\n",
    "    Median Rank 계산 함수\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (list of list): 각 query에 대한 예측된 결과 리스트\n",
    "    targets (list): 각 query에 대한 실제 정답\n",
    "    \n",
    "    Returns:\n",
    "    float: Median Rank 값\n",
    "    \"\"\"\n",
    "    ranks = []\n",
    "    for i in range(len(targets)):\n",
    "        if targets[i] in predictions[i]:\n",
    "            ranks.append(predictions[i].index(targets[i]) + 1)\n",
    "        else:\n",
    "            ranks.append(len(predictions[i]) + 1)  # 정답이 없으면 최대 rank로 설정\n",
    "    \n",
    "    return np.median(ranks)\n",
    "\n",
    "# Recall@1, Recall@5, Recall@10 계산 함수\n",
    "def compute_all_metrics(predictions, targets):\n",
    "    \"\"\"\n",
    "    Recall@1, Recall@5, Recall@10, Median Rank, Mean Rank를 계산하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (list of list): 각 query에 대한 예측된 결과 리스트\n",
    "    targets (list): 각 query에 대한 실제 정답\n",
    "    \n",
    "    Returns:\n",
    "    dict: 각 메트릭의 결과를 담은 사전\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'Recall@1': compute_recall_at_k(predictions, targets, 1),\n",
    "        'Recall@5': compute_recall_at_k(predictions, targets, 5),\n",
    "        'Recall@10': compute_recall_at_k(predictions, targets, 10),\n",
    "        'Median Rank': compute_median_rank(predictions, targets),\n",
    "        'Mean Rank': compute_mean_rank(predictions, targets)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [05:24<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "for k, v in tqdm(labels.items()):\n",
    "    \n",
    "    docs = json_databases['retriever'].invoke(v)\n",
    "    \n",
    "    preds = []\n",
    "    for doc in docs:\n",
    "        normalized_path = unicodedata.normalize('NFC', doc.metadata['source'])\n",
    "        full_path = os.path.normpath(\n",
    "            os.path.join(\n",
    "                base_directory, normalized_path.lstrip('./')\n",
    "            )\n",
    "        ) if not os.path.isabs(normalized_path) else normalized_path\n",
    "        json_title = os.path.splitext(os.path.basename(full_path))[0]\n",
    "        preds.append(json_title)\n",
    "        \n",
    "    predictions.append(preds)\n",
    "    targets.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recall@1': 0.318, 'Recall@5': 0.566, 'Recall@10': 0.663, 'Median Rank': 4.0, 'Mean Rank': 5.512}\n"
     ]
    }
   ],
   "source": [
    "metrics = compute_all_metrics(predictions, targets)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
